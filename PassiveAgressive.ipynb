{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNnZZbV+/8zDY2gDg3Dew6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/its3alih/Thesis/blob/main/PassiveAgressive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FIRST"
      ],
      "metadata": {
        "id": "zBd6U4TfQViw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haRqdWpXIgN6",
        "outputId": "bd924062-9b2d-4955-a6d8-bc1b4959eaf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           I       0.95      0.94      0.94       548\n",
            "           O       1.00      1.00      1.00     11201\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.97      0.97      0.97     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9947\n",
            "Precision: 0.9947\n",
            "Recall: 0.9947\n",
            "F1 Score: 0.9947\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IO.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train Passive Aggressive model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=42)\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data (BI.xlsx)\n",
        "sentences, tags = load_excel_data(\"/content/BI.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train Passive Aggressive model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=42)\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29zv8nt6JdZi",
        "outputId": "12de3fa6-5174-4bcc-82de-88270df03d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.98      0.98      0.98       251\n",
            "          BO       0.72      0.79      0.75       197\n",
            "           I       0.91      0.91      0.91       294\n",
            "          IO       0.99      0.99      0.99     11007\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.90      0.92      0.91     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9860\n",
            "Precision: 0.9865\n",
            "Recall: 0.9860\n",
            "F1 Score: 0.9862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data (BIES.xlsx)\n",
        "sentences, tags = load_excel_data(\"/content/BIES.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train Passive Aggressive model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=42)\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f1iw4QVKGEi",
        "outputId": "f372b928-1bcb-4108-8599-aba22e11541b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.98      0.98      0.98       247\n",
            "          BO       0.73      0.77      0.75       190\n",
            "           E       0.89      0.95      0.92       248\n",
            "          EO       0.95      0.92      0.93       257\n",
            "           I       0.89      0.85      0.87        46\n",
            "          IO       0.99      0.99      0.99     10750\n",
            "           S       1.00      1.00      1.00         4\n",
            "          SO       0.67      0.57      0.62         7\n",
            "\n",
            "    accuracy                           0.98     11749\n",
            "   macro avg       0.89      0.88      0.88     11749\n",
            "weighted avg       0.98      0.98      0.98     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9842\n",
            "Precision: 0.9845\n",
            "Recall: 0.9842\n",
            "F1 Score: 0.9843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data (IE.xlsx)\n",
        "sentences, tags = load_excel_data(\"/content/IE.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train Passive Aggressive model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=42)\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk7sRndgKS8e",
        "outputId": "9476ab2c-d8b1-4d66-c32e-6e5182a433b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       0.89      0.93      0.91       252\n",
            "          EO       0.92      0.93      0.93       264\n",
            "           I       0.95      0.97      0.96       293\n",
            "          IO       1.00      0.99      1.00     10940\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.94      0.96      0.95     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9911\n",
            "Precision: 0.9913\n",
            "Recall: 0.9911\n",
            "F1 Score: 0.9912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data (IOB.xlsx)\n",
        "sentences, tags = load_excel_data(\"/content/IOB.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train Passive Aggressive model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=42)\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz2D5hGvLLV7",
        "outputId": "6c0b1b96-5031-4c1d-c12d-d5b960db1912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.98      0.98      0.98       252\n",
            "           I       0.90      0.95      0.93       296\n",
            "           O       1.00      1.00      1.00     11201\n",
            "\n",
            "    accuracy                           1.00     11749\n",
            "   macro avg       0.96      0.98      0.97     11749\n",
            "weighted avg       1.00      1.00      1.00     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9953\n",
            "Precision: 0.9954\n",
            "Recall: 0.9953\n",
            "F1 Score: 0.9954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data (IOBES.xlsx)\n",
        "sentences, tags = load_excel_data(\"/content/IOBES.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train Passive Aggressive model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=42)\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2pCo_2WLc3X",
        "outputId": "841b2b0b-e73b-4ee5-c136-b4315ffbfc8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.99      0.97      0.98       247\n",
            "           E       0.89      0.95      0.92       248\n",
            "           I       0.87      0.87      0.87        46\n",
            "           O       1.00      1.00      1.00     11204\n",
            "           S       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.95      0.96      0.95     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9948\n",
            "Precision: 0.9950\n",
            "Recall: 0.9948\n",
            "F1 Score: 0.9949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data (IOE.xlsx)\n",
        "sentences, tags = load_excel_data(\"/content/IOE.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train Passive Aggressive model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=42)\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnis5gdWLs0V",
        "outputId": "c8888d6f-2204-4f75-e8cc-7606e152eb34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       0.89      0.94      0.91       252\n",
            "           I       0.97      0.97      0.97       293\n",
            "           O       1.00      1.00      1.00     11204\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.95      0.97      0.96     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9946\n",
            "Precision: 0.9948\n",
            "Recall: 0.9946\n",
            "F1 Score: 0.9947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SECOND"
      ],
      "metadata": {
        "id": "KYN7seC2QX64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IO.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train Passive Aggressive model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=42)\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAiZ05EPQbfP",
        "outputId": "3eac4faf-eb66-4ebf-844c-19d475f12190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           I       0.95      0.92      0.94       591\n",
            "           O       1.00      1.00      1.00     11158\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.97      0.96      0.97     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9938\n",
            "Precision: 0.9937\n",
            "Recall: 0.9938\n",
            "F1 Score: 0.9937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data (BI.xlsx)\n",
        "sentences, tags = load_excel_data(\"/content/BI.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train Passive Aggressive model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=42)\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMeWz0CxRFwo",
        "outputId": "9394a6b7-b920-435c-f884-1f78266f743d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.99      0.99      0.99       266\n",
            "          BO       0.75      0.80      0.77       210\n",
            "           I       0.89      0.94      0.91       325\n",
            "          IO       0.99      0.99      0.99     10948\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.91      0.93      0.92     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9864\n",
            "Precision: 0.9868\n",
            "Recall: 0.9864\n",
            "F1 Score: 0.9866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data (BIES.xlsx)\n",
        "sentences, tags = load_excel_data(\"/content/BIES.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train Passive Aggressive model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=42)\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmW4r8nmRXvB",
        "outputId": "f5024f70-43b9-48fd-e267-4cd43554da28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.99      0.99      0.99       262\n",
            "          BO       0.78      0.73      0.76       202\n",
            "           E       0.91      0.94      0.93       271\n",
            "          EO       0.95      0.91      0.93       266\n",
            "           I       0.85      0.94      0.89        54\n",
            "          IO       0.99      0.99      0.99     10682\n",
            "           S       1.00      1.00      1.00         4\n",
            "          SO       0.36      0.50      0.42         8\n",
            "\n",
            "    accuracy                           0.98     11749\n",
            "   macro avg       0.85      0.88      0.86     11749\n",
            "weighted avg       0.98      0.98      0.98     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9835\n",
            "Precision: 0.9835\n",
            "Recall: 0.9835\n",
            "F1 Score: 0.9835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data (IE.xlsx)\n",
        "sentences, tags = load_excel_data(\"/content/IE.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train Passive Aggressive model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=42)\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58UqxQjkRmjV",
        "outputId": "bbc80a1f-36b1-4990-b012-a255142fc8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       0.92      0.91      0.92       275\n",
            "          EO       0.94      0.92      0.93       274\n",
            "           I       0.96      0.97      0.97       316\n",
            "          IO       1.00      1.00      1.00     10884\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.95      0.95      0.95     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9912\n",
            "Precision: 0.9912\n",
            "Recall: 0.9912\n",
            "F1 Score: 0.9912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data (IOB.xlsx)\n",
        "sentences, tags = load_excel_data(\"/content/IOB.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train Passive Aggressive model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=42)\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlJESBGHRxgW",
        "outputId": "dbef51d3-c1eb-4dc3-d883-d6dea80eb1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.99      0.98      0.99       266\n",
            "           I       0.90      0.94      0.92       325\n",
            "           O       1.00      1.00      1.00     11158\n",
            "\n",
            "    accuracy                           1.00     11749\n",
            "   macro avg       0.96      0.98      0.97     11749\n",
            "weighted avg       1.00      1.00      1.00     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9951\n",
            "Precision: 0.9952\n",
            "Recall: 0.9951\n",
            "F1 Score: 0.9951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data (IOBES.xlsx)\n",
        "sentences, tags = load_excel_data(\"/content/IOBES.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train Passive Aggressive model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=42)\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1z8FTeQSEnF",
        "outputId": "ecf227d3-21d2-4a51-e554-c51d51e04232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.99      0.98      0.99       262\n",
            "           E       0.92      0.93      0.93       271\n",
            "           I       0.79      0.93      0.85        54\n",
            "           O       1.00      1.00      1.00     11158\n",
            "           S       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.94      0.97      0.95     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9947\n",
            "Precision: 0.9949\n",
            "Recall: 0.9947\n",
            "F1 Score: 0.9948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data (IOE.xlsx)\n",
        "sentences, tags = load_excel_data(\"/content/IOE.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train Passive Aggressive model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = PassiveAggressiveClassifier(max_iter=1000, random_state=42)\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "id": "fH47Ak1wSSVq",
        "outputId": "876e6f3a-cb0b-4729-9276-199797a51ec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       0.91      0.96      0.93       275\n",
            "           I       0.97      0.98      0.97       316\n",
            "           O       1.00      1.00      1.00     11158\n",
            "\n",
            "    accuracy                           1.00     11749\n",
            "   macro avg       0.96      0.98      0.97     11749\n",
            "weighted avg       1.00      1.00      1.00     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9953\n",
            "Precision: 0.9954\n",
            "Recall: 0.9953\n",
            "F1 Score: 0.9954\n"
          ]
        }
      ]
    }
  ]
}