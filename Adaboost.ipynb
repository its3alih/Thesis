{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBJe7wurBLnJ/qznUd8HCM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/its3alih/Thesis/blob/main/Adaboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FIRST"
      ],
      "metadata": {
        "id": "xIQI_tp28w-Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rsynS5jBWeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72116e27-71db-48f6-f2a5-8989a5482368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           I       0.96      0.70      0.81       548\n",
            "           O       0.99      1.00      0.99     11201\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.98      0.85      0.90     11749\n",
            "weighted avg       0.98      0.99      0.98     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9850\n",
            "Precision: 0.9848\n",
            "Recall: 0.9850\n",
            "F1 Score: 0.9839\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IO.xlsx\")  # Adjust path if needed\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train AdaBoost model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=42)  # Use default decision tree base estimator\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Load Excel Data for IOB\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IOB.xlsx\")  # Adjust path if needed\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train AdaBoost model for IOB data\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=42)  # AdaBoost with default decision tree as base estimator\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz-rYMPLCx54",
        "outputId": "c5a879a7-2629-47ed-9c93-22fac6841a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.96      0.76      0.85       252\n",
            "           I       0.97      0.66      0.78       296\n",
            "           O       0.99      1.00      0.99     11201\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.97      0.81      0.87     11749\n",
            "weighted avg       0.98      0.99      0.98     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9850\n",
            "Precision: 0.9848\n",
            "Recall: 0.9850\n",
            "F1 Score: 0.9838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Load Excel Data for IOE\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IOE.xlsx\")  # Adjust path if needed\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train AdaBoost model for IOE data\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=42)  # AdaBoost with default decision tree as base estimator\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn7GN07VDIDf",
        "outputId": "25437753-9fbc-4306-87ea-a80f22b182a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       0.82      0.65      0.72       252\n",
            "           I       0.96      0.66      0.78       293\n",
            "           O       0.99      1.00      0.99     11204\n",
            "\n",
            "    accuracy                           0.98     11749\n",
            "   macro avg       0.92      0.77      0.83     11749\n",
            "weighted avg       0.98      0.98      0.98     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9826\n",
            "Precision: 0.9816\n",
            "Recall: 0.9826\n",
            "F1 Score: 0.9811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Load Excel Data for IOBES\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IOBES.xlsx\")  # Adjust path if needed\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train AdaBoost model for IOBES data\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=42)  # AdaBoost with default decision tree as base estimator\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpVjrUIDEtt2",
        "outputId": "5244328d-8a2b-4aa7-d344-21f869a74531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.96      0.78      0.86       247\n",
            "           E       1.00      0.14      0.25       248\n",
            "           I       0.00      0.00      0.00        46\n",
            "           O       0.97      1.00      0.99     11204\n",
            "           S       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.97     11749\n",
            "   macro avg       0.59      0.38      0.42     11749\n",
            "weighted avg       0.97      0.97      0.96     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9723\n",
            "Precision: 0.9687\n",
            "Recall: 0.9723\n",
            "F1 Score: 0.9633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Load Excel Data for IE\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IE.xlsx\")  # Adjust path if needed\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train AdaBoost model for IE data\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=42)  # AdaBoost with default decision tree as base estimator\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRksGFaAFCUv",
        "outputId": "2a142828-9078-4312-d3be-d22c9f1ae4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       1.00      0.14      0.24       252\n",
            "          EO       0.97      0.80      0.88       264\n",
            "           I       0.96      0.66      0.78       293\n",
            "          IO       0.97      1.00      0.98     10940\n",
            "\n",
            "    accuracy                           0.97     11749\n",
            "   macro avg       0.98      0.65      0.72     11749\n",
            "weighted avg       0.97      0.97      0.96     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9675\n",
            "Precision: 0.9681\n",
            "Recall: 0.9675\n",
            "F1 Score: 0.9596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Load Excel Data for BI\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/BI.xlsx\")  # Adjust path if needed\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train AdaBoost model for BI data\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=42)  # AdaBoost with default decision tree as base estimator\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WCwXuTZFYXW",
        "outputId": "9519ac6d-2a33-4bfc-8ee9-b04a943f2e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       1.00      0.02      0.03       251\n",
            "          BO       0.00      0.00      0.00       197\n",
            "           I       0.96      0.65      0.78       294\n",
            "          IO       0.95      1.00      0.98     11007\n",
            "\n",
            "    accuracy                           0.95     11749\n",
            "   macro avg       0.73      0.42      0.45     11749\n",
            "weighted avg       0.94      0.95      0.93     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9528\n",
            "Precision: 0.9378\n",
            "Recall: 0.9528\n",
            "F1 Score: 0.9339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Load Excel Data for BIES\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/BIES.xlsx\")  # Adjust path if needed\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train AdaBoost model for BIES data\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=42)  # AdaBoost with default decision tree as base estimator\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "id": "jbfrb0Z1Fn6R",
        "outputId": "b0a92bf4-c178-4517-b984-1cae8d04305c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.96      0.78      0.86       247\n",
            "          BO       0.00      0.00      0.00       190\n",
            "           E       1.00      0.14      0.25       248\n",
            "          EO       0.00      0.00      0.00       257\n",
            "           I       0.00      0.00      0.00        46\n",
            "          IO       0.93      1.00      0.97     10750\n",
            "           S       0.00      0.00      0.00         4\n",
            "          SO       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.93     11749\n",
            "   macro avg       0.36      0.24      0.26     11749\n",
            "weighted avg       0.90      0.93      0.91     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9337\n",
            "Precision: 0.8951\n",
            "Recall: 0.9337\n",
            "F1 Score: 0.9063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SECOND"
      ],
      "metadata": {
        "id": "nuHkCBR-80Xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IO.xlsx\")  # Adjust path if needed\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train AdaBoost model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=42)  # Use default decision tree base estimator\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te-5ov7881sH",
        "outputId": "62e30453-80b5-42b3-a674-981abfa69d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           I       0.98      0.66      0.79       591\n",
            "           O       0.98      1.00      0.99     11158\n",
            "\n",
            "    accuracy                           0.98     11749\n",
            "   macro avg       0.98      0.83      0.89     11749\n",
            "weighted avg       0.98      0.98      0.98     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9826\n",
            "Precision: 0.9826\n",
            "Recall: 0.9826\n",
            "F1 Score: 0.9809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Load Excel Data for IOB\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IOB.xlsx\")  # Adjust path if needed\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train AdaBoost model for IOB data\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=42)  # AdaBoost with default decision tree as base estimator\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h214tTi9UBk",
        "outputId": "65d1a46c-dd1c-4d57-9ba9-2559830e7467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.98      0.74      0.84       266\n",
            "           I       0.98      0.61      0.75       325\n",
            "           O       0.98      1.00      0.99     11158\n",
            "\n",
            "    accuracy                           0.98     11749\n",
            "   macro avg       0.98      0.78      0.86     11749\n",
            "weighted avg       0.98      0.98      0.98     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9826\n",
            "Precision: 0.9825\n",
            "Recall: 0.9826\n",
            "F1 Score: 0.9809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Load Excel Data for IOE\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IOE.xlsx\")  # Adjust path if needed\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train AdaBoost model for IOE data\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=42)  # AdaBoost with default decision tree as base estimator\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5gVRzCi9cFw",
        "outputId": "ac947f19-a8fa-4d81-bf3c-31e7800ed16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       0.85      0.62      0.71       275\n",
            "           I       0.98      0.62      0.76       316\n",
            "           O       0.98      1.00      0.99     11158\n",
            "\n",
            "    accuracy                           0.98     11749\n",
            "   macro avg       0.94      0.75      0.82     11749\n",
            "weighted avg       0.98      0.98      0.98     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9803\n",
            "Precision: 0.9794\n",
            "Recall: 0.9803\n",
            "F1 Score: 0.9782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Load Excel Data for IOBES\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IOBES.xlsx\")  # Adjust path if needed\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train AdaBoost model for IOBES data\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=42)  # AdaBoost with default decision tree as base estimator\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5emJlh1h9jve",
        "outputId": "0838b21c-9e2e-4292-ff2f-1760d62e025c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.98      0.75      0.85       262\n",
            "           E       0.85      0.63      0.72       271\n",
            "           I       0.00      0.00      0.00        54\n",
            "           O       0.98      1.00      0.99     11158\n",
            "           S       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.98     11749\n",
            "   macro avg       0.56      0.47      0.51     11749\n",
            "weighted avg       0.97      0.98      0.98     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9803\n",
            "Precision: 0.9746\n",
            "Recall: 0.9803\n",
            "F1 Score: 0.9766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Load Excel Data for IE\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IE.xlsx\")  # Adjust path if needed\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train AdaBoost model for IE data\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=42)  # AdaBoost with default decision tree as base estimator\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMZjQy6v9ufH",
        "outputId": "380b25bf-47c6-46d3-eaf3-353b0da6e0cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       1.00      0.13      0.23       275\n",
            "          EO       0.00      0.00      0.00       274\n",
            "           I       0.98      0.62      0.76       316\n",
            "          IO       0.94      1.00      0.97     10884\n",
            "\n",
            "    accuracy                           0.95     11749\n",
            "   macro avg       0.73      0.44      0.49     11749\n",
            "weighted avg       0.93      0.95      0.93     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9458\n",
            "Precision: 0.9253\n",
            "Recall: 0.9458\n",
            "F1 Score: 0.9258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Load Excel Data for BI\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/BI.xlsx\")  # Adjust path if needed\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train AdaBoost model for BI data\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=42)  # AdaBoost with default decision tree as base estimator\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qcT9D5w93EA",
        "outputId": "a2351bbd-edb6-499b-e5cf-14c24962e227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.98      0.74      0.84       266\n",
            "          BO       0.00      0.00      0.00       210\n",
            "           I       1.00      0.03      0.05       325\n",
            "          IO       0.95      1.00      0.97     10948\n",
            "\n",
            "    accuracy                           0.95     11749\n",
            "   macro avg       0.73      0.44      0.47     11749\n",
            "weighted avg       0.93      0.95      0.93     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9490\n",
            "Precision: 0.9337\n",
            "Recall: 0.9490\n",
            "F1 Score: 0.9276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Load Excel Data for BIES\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/BIES.xlsx\")  # Adjust path if needed\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train AdaBoost model for BIES data\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=42)  # AdaBoost with default decision tree as base estimator\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOY3KIg7-lgc",
        "outputId": "abf58ad5-f08f-4204-9a93-89733b3405f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.98      0.75      0.85       262\n",
            "          BO       0.00      0.00      0.00       202\n",
            "           E       0.00      0.00      0.00       271\n",
            "          EO       0.00      0.00      0.00       266\n",
            "           I       0.00      0.00      0.00        54\n",
            "          IO       0.92      1.00      0.96     10682\n",
            "           S       0.00      0.00      0.00         4\n",
            "          SO       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.93     11749\n",
            "   macro avg       0.24      0.22      0.23     11749\n",
            "weighted avg       0.86      0.93      0.89     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9256\n",
            "Precision: 0.8627\n",
            "Recall: 0.9256\n",
            "F1 Score: 0.8924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}