{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYzffRkpNAUw9CCNjD21Br",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/its3alih/Thesis/blob/main/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FIRST\n"
      ],
      "metadata": {
        "id": "g8fTldB25TEj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MZZOznM6-vH",
        "outputId": "28e14cdb-bc37-4597-d9e9-b7858763bca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           I       0.95      0.95      0.95       548\n",
            "           O       1.00      1.00      1.00     11201\n",
            "\n",
            "    accuracy                           1.00     11749\n",
            "   macro avg       0.97      0.97      0.97     11749\n",
            "weighted avg       1.00      1.00      1.00     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9954\n",
            "Precision: 0.9954\n",
            "Recall: 0.9954\n",
            "F1 Score: 0.9954\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IO.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train SVM model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = LinearSVC()\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data with IOB Tags\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Extract features per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare token-level data\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IOB.xlsx\")  # Make sure this is the IOB-tagged file\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Vectorize and Train SVM\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = LinearSVC()\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and Evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeUCEKYE8GFC",
        "outputId": "74bf01fe-ea4a-4e73-ef17-f6abbdc5a9d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.98      0.98      0.98       252\n",
            "           I       0.93      0.93      0.93       296\n",
            "           O       1.00      1.00      1.00     11201\n",
            "\n",
            "    accuracy                           1.00     11749\n",
            "   macro avg       0.97      0.97      0.97     11749\n",
            "weighted avg       1.00      1.00      1.00     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9957\n",
            "Precision: 0.9956\n",
            "Recall: 0.9957\n",
            "F1 Score: 0.9957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data with IOE Tags\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # Sentence boundary\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Extract token-level features\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare data for SVM\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load IOE-tagged data\n",
        "sentences, tags = load_excel_data(\"/content/IOE.xlsx\")  # Make sure this file uses IOE tags\n",
        "\n",
        "# 5. Extract features and labels\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Train SVM\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = LinearSVC()\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 7. Predict and Evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgmXYAr_8kNm",
        "outputId": "1637b801-1670-4917-80d3-15ec3a7e27cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       0.91      0.92      0.92       252\n",
            "           I       0.98      0.97      0.97       293\n",
            "           O       1.00      1.00      1.00     11204\n",
            "\n",
            "    accuracy                           1.00     11749\n",
            "   macro avg       0.96      0.96      0.96     11749\n",
            "weighted avg       1.00      1.00      1.00     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9952\n",
            "Precision: 0.9953\n",
            "Recall: 0.9952\n",
            "F1 Score: 0.9952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data with IOBES Tags\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # Sentence boundary\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Extract token-level features\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare data for SVM\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load IOBES-tagged data\n",
        "sentences, tags = load_excel_data(\"/content/IOBES.xlsx\")  # Make sure this file uses IOBES tags\n",
        "\n",
        "# 5. Extract features and labels\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Train SVM\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = LinearSVC()\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 7. Predict and Evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iqzf8IeP83GL",
        "outputId": "fe741e61-9878-4cd2-d5c7-1093638e84a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.99      0.98      0.99       247\n",
            "           E       0.90      0.92      0.91       248\n",
            "           I       0.95      0.85      0.90        46\n",
            "           O       1.00      1.00      1.00     11204\n",
            "           S       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00     11749\n",
            "   macro avg       0.97      0.95      0.96     11749\n",
            "weighted avg       1.00      1.00      1.00     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9952\n",
            "Precision: 0.9953\n",
            "Recall: 0.9952\n",
            "F1 Score: 0.9952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data with IE Tags\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # Sentence end\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Extract token-level features\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare data\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load IE-tagged data\n",
        "sentences, tags = load_excel_data(\"/content/IE.xlsx\")  # Make sure this file uses IE tagging scheme\n",
        "\n",
        "# 5. Extract features and labels\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Train SVM\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = LinearSVC()\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 7. Predict and Evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWSZH5GD9Knu",
        "outputId": "8a987747-4803-4b1e-c15c-d2774f9f9a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       0.90      0.92      0.91       252\n",
            "          EO       0.96      0.93      0.95       264\n",
            "           I       0.98      0.97      0.97       293\n",
            "          IO       1.00      1.00      1.00     10940\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.96      0.95      0.96     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9928\n",
            "Precision: 0.9928\n",
            "Recall: 0.9928\n",
            "F1 Score: 0.9928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data with BI Tags\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # Sentence end\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature Extraction for Each Token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare Features and Labels\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load BI-tagged data\n",
        "sentences, tags = load_excel_data(\"/content/BI.xlsx\")  # Ensure this is BI tagged\n",
        "\n",
        "# 5. Extract Features and Labels\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Train SVM Model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = LinearSVC()\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 7. Predict and Evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J4Qzbxi9mVp",
        "outputId": "c007533d-0b6a-4da0-a1f3-47bd311fa8ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.98      0.98      0.98       251\n",
            "          BO       0.76      0.80      0.78       197\n",
            "           I       0.92      0.93      0.93       294\n",
            "          IO       0.99      0.99      0.99     11007\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.91      0.92      0.92     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9878\n",
            "Precision: 0.9880\n",
            "Recall: 0.9878\n",
            "F1 Score: 0.9879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel with BIES Tags\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # Sentence end\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Extract Features for Each Token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Format Features and Labels\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load BIES Data\n",
        "sentences, tags = load_excel_data(\"/content/BIES.xlsx\")  # Update with your BIES-labeled Excel path\n",
        "\n",
        "# 5. Prepare Feature Vectors and Labels\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Train SVM Model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = LinearSVC()\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 7. Evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "id": "w__VHJgv965s",
        "outputId": "e3aa6eb9-0d34-490e-da2d-e5301687e11d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.98      0.98      0.98       247\n",
            "          BO       0.77      0.79      0.78       190\n",
            "           E       0.89      0.92      0.91       248\n",
            "          EO       0.96      0.93      0.94       257\n",
            "           I       0.95      0.85      0.90        46\n",
            "          IO       0.99      0.99      0.99     10750\n",
            "           S       1.00      1.00      1.00         4\n",
            "          SO       0.67      0.57      0.62         7\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.90      0.88      0.89     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9851\n",
            "Precision: 0.9852\n",
            "Recall: 0.9851\n",
            "F1 Score: 0.9851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SECOND\n",
        "\n"
      ],
      "metadata": {
        "id": "VLipZseYR0r6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature extraction per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare dataset\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IO.xlsx\")\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build and train SVM model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = LinearSVC()\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bzpwg3vw7dkk",
        "outputId": "63ced8ef-1624-49eb-85d2-44755608204d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           I       0.95      0.95      0.95       591\n",
            "           O       1.00      1.00      1.00     11158\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.97      0.97      0.97     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9950\n",
            "Precision: 0.9950\n",
            "Recall: 0.9950\n",
            "F1 Score: 0.9950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data with IOB Tags\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # End of sentence\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Extract features per token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare token-level data\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load and split data\n",
        "sentences, tags = load_excel_data(\"/content/IOB.xlsx\")  # Make sure this is the IOB-tagged file\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Vectorize and Train SVM\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = LinearSVC()\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and Evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNNifdHZ7pv8",
        "outputId": "70038c7c-34cb-425a-9255-42ed45614a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.99      0.99      0.99       266\n",
            "           I       0.93      0.92      0.93       325\n",
            "           O       1.00      1.00      1.00     11158\n",
            "\n",
            "    accuracy                           1.00     11749\n",
            "   macro avg       0.97      0.97      0.97     11749\n",
            "weighted avg       1.00      1.00      1.00     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9956\n",
            "Precision: 0.9956\n",
            "Recall: 0.9956\n",
            "F1 Score: 0.9956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data with IOE Tags\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # Sentence boundary\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Extract token-level features\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare data for SVM\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load IOE-tagged data\n",
        "sentences, tags = load_excel_data(\"/content/IOE.xlsx\")  # Make sure this file uses IOE tags\n",
        "\n",
        "# 5. Extract features and labels\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Train SVM\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = LinearSVC()\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 7. Predict and Evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt6m26vq7yqK",
        "outputId": "4ed35a20-fc44-4ea3-9f9d-1be575fd957b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       0.93      0.92      0.92       275\n",
            "           I       0.97      0.98      0.98       316\n",
            "           O       1.00      1.00      1.00     11158\n",
            "\n",
            "    accuracy                           1.00     11749\n",
            "   macro avg       0.97      0.96      0.97     11749\n",
            "weighted avg       1.00      1.00      1.00     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9952\n",
            "Precision: 0.9952\n",
            "Recall: 0.9952\n",
            "F1 Score: 0.9952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data with IOBES Tags\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # Sentence boundary\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Extract token-level features\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare data for SVM\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load IOBES-tagged data\n",
        "sentences, tags = load_excel_data(\"/content/IOBES.xlsx\")  # Make sure this file uses IOBES tags\n",
        "\n",
        "# 5. Extract features and labels\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Train SVM\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = LinearSVC()\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 7. Predict and Evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi0MXHcc76Ke",
        "outputId": "9d115873-beef-4c11-d0fa-4ef93eef16e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.99      0.99      0.99       262\n",
            "           E       0.93      0.92      0.92       271\n",
            "           I       0.86      0.93      0.89        54\n",
            "           O       1.00      1.00      1.00     11158\n",
            "           S       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00     11749\n",
            "   macro avg       0.96      0.97      0.96     11749\n",
            "weighted avg       1.00      1.00      1.00     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9951\n",
            "Precision: 0.9952\n",
            "Recall: 0.9951\n",
            "F1 Score: 0.9952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data with IE Tags\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # Sentence end\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Extract token-level features\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare data\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load IE-tagged data\n",
        "sentences, tags = load_excel_data(\"/content/IE.xlsx\")  # Make sure this file uses IE tagging scheme\n",
        "\n",
        "# 5. Extract features and labels\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Train SVM\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = LinearSVC()\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 7. Predict and Evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XZlA15N8By-",
        "outputId": "a52f80cd-f137-4bbe-9a31-a447b6363878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           E       0.93      0.91      0.92       275\n",
            "          EO       0.97      0.92      0.94       274\n",
            "           I       0.97      0.98      0.98       316\n",
            "          IO       1.00      1.00      1.00     10884\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.97      0.95      0.96     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9928\n",
            "Precision: 0.9927\n",
            "Recall: 0.9928\n",
            "F1 Score: 0.9927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel Data with BI Tags\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # Sentence end\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Feature Extraction for Each Token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Prepare Features and Labels\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load BI-tagged data\n",
        "sentences, tags = load_excel_data(\"/content/BI.xlsx\")  # Ensure this is BI tagged\n",
        "\n",
        "# 5. Extract Features and Labels\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Train SVM Model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = LinearSVC()\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 7. Predict and Evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7i4sIYt8Kqa",
        "outputId": "3520d616-fc2e-4edb-e6d1-1415383fe335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.99      0.99      0.99       266\n",
            "          BO       0.77      0.82      0.79       210\n",
            "           I       0.93      0.92      0.93       325\n",
            "          IO       0.99      0.99      0.99     10948\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.92      0.93      0.93     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9879\n",
            "Precision: 0.9881\n",
            "Recall: 0.9879\n",
            "F1 Score: 0.9880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# 1. Load Excel with BIES Tags\n",
        "def load_excel_data(file_path):\n",
        "    df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
        "    df = df[['Word i', 'Word i entity tag']].dropna()\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label = [], []\n",
        "    for word, tag in zip(df['Word i'], df['Word i entity tag']):\n",
        "        if str(word).strip() in ['.', '؟']:  # Sentence end\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                labels.append(label)\n",
        "                sentence, label = [], []\n",
        "        else:\n",
        "            sentence.append(str(word).strip())\n",
        "            label.append(str(tag).strip())\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# 2. Extract Features for Each Token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'is_upper': word.isupper(),\n",
        "        'is_title': word.istitle(),\n",
        "        'is_digit': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:is_title': word1.istitle(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# 3. Format Features and Labels\n",
        "def prepare_data(sentences, labels):\n",
        "    X, y = [], []\n",
        "    for sent, label_seq in zip(sentences, labels):\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent, i)\n",
        "            X.append(feats)\n",
        "            y.append(label_seq[i])\n",
        "    return X, y\n",
        "\n",
        "# 4. Load BIES Data\n",
        "sentences, tags = load_excel_data(\"/content/BIES.xlsx\")  # Update with your BIES-labeled Excel path\n",
        "\n",
        "# 5. Prepare Feature Vectors and Labels\n",
        "X_all, y_all = prepare_data(sentences, tags)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Train SVM Model\n",
        "vec = DictVectorizer(sparse=True)\n",
        "clf = LinearSVC()\n",
        "pipeline = make_pipeline(vec, clf)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 7. Evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "275nvEw48YQZ",
        "outputId": "0d5b5490-5aab-4730-984e-36af62ba980b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.99      0.99      0.99       262\n",
            "          BO       0.78      0.82      0.80       202\n",
            "           E       0.93      0.92      0.92       271\n",
            "          EO       0.96      0.93      0.94       266\n",
            "           I       0.86      0.93      0.89        54\n",
            "          IO       0.99      0.99      0.99     10682\n",
            "           S       1.00      1.00      1.00         4\n",
            "          SO       0.67      0.50      0.57         8\n",
            "\n",
            "    accuracy                           0.99     11749\n",
            "   macro avg       0.90      0.88      0.89     11749\n",
            "weighted avg       0.99      0.99      0.99     11749\n",
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.9854\n",
            "Precision: 0.9856\n",
            "Recall: 0.9854\n",
            "F1 Score: 0.9855\n"
          ]
        }
      ]
    }
  ]
}